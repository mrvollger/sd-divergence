import os
import sys
import math
import pandas as pd
from snakemake.utils import min_version

min_version("6.0")

SDIR = os.path.realpath(os.path.dirname(srcdir("Snakefile")))
shell.prefix(f"set -eo pipefail;")


configfile: "config/config.yaml"


tbl = pd.read_csv(config["manifest"], sep="\t")
tbl.set_index("sample", inplace=True)
fai = config["ref"] + ".fai"
assert os.path.exists(fai), f"{fai} not found"

TEMP_DIR = config.pop("tempdir", "temp")
if TEMP_DIR != "temp":
    if os.path.exists("temp"):
        if os.path.islink("temp") and os.path.realpath("temp") == os.path.realpath(
            TEMP_DIR
        ):
            print("The temp dir has already been linked.")
        else:
            sys.exit("temp/ already in use, please move it before running.")
    else:
        shell("ln -s {TEMP_DIR} temp")


wildcard_constraints:
    sm="|".join(tbl.index) + "|all",


rule all:
    input:
        uncallable="results/uncallable_regions.bed.gz",
        snv="results/snv_count_annotated_haplotype_coverage.bed.gz",
        all_snv="results/all_snv_exploded.bed.gz",
        filtered_sv_pop_snv=expand(
            "results/syntenic_and_callable/snv_{sm}.bed.gz", sm=tbl.index
        ),
        cumulative_divergence="results/figures/cumulative_divergence.svg",
        called_regions="results/figures/callable_space.svg",


rule make_windows:
    input:
        fai=fai,
        annotation_files=config["annotation_files"].values(),
    output:
        temp("temp/windows.bed.gz"),
    log:
        "logs/windows.log",
    conda:
        "envs/env.yml"
    params:
        window_size=config["window_size"],
        step_size=config["step_size"],
        annotation_names="\t".join(config["annotation_files"].keys()),
    threads: 1
    shell:
        """
        bedtools makewindows -g {input.fai} -w {params.window_size} -s {params.step_size} \
            | bedtools sort -i - \
            | gzip -c > {output}
        """


rule syntenic_and_callable:
    input:
        callable=lambda w: tbl.loc[w.sm][f"h{w.h}_callable"],
        aln=lambda w: tbl.loc[w.sm][f"h{w.h}_aln"],
    output:
        "results/syntenic_and_callable/{sm}_{h}.bed.gz",
    log:
        "logs/syntenic.{sm}_{h}.log",
    conda:
        "envs/env.yml"
    params:
        min_syntenic_size=config["min_syntenic_size"],
    threads: 1
    shell:
        """
        bedtools intersect -a {input.callable} \
            -b <( bedtools sort -i {input.aln} | awk '$3 - $2 >= {params.min_syntenic_size}' ) \
            | bedtools sort -i - \
            | bedtools merge -i - \
            | sed 's/$/\\t{wildcards.sm}_{wildcards.h}/g' \
            | gzip -c > {output}
        """


rule explode_snv:
    input:
        bed=lambda w: tbl.loc[w.sm][f"snv"],
    output:
        snv=temp("temp/syntenic_and_callable/snv_explode_{sm}.bed.gz"),
    log:
        "logs/explode_snv.{sm}.log",
    conda:
        "envs/env.yml"
    threads: 1
    script:
        "scripts/explode_snv.py"


rule filter_snv_by_syntenic:
    input:
        snv=rules.explode_snv.output.snv,
        callable=rules.syntenic_and_callable.output,
    output:
        snv=temp("temp/syntenic_and_callable/snv_{sm}_{h}.bed.gz"),
    log:
        "logs/snv_by_syntenic.{sm}_{h}.log",
    conda:
        "envs/env.yml"
    threads: 1
    shell:
        """
        gunzip -c {input.snv} \
            | awk -F$'\\t' -v pat="h{wildcards.h}|HAP" '$15 ~ pat' \
            | bedtools intersect -u \
                -a - \
                -b <(gunzip -c {input.callable}) \
                -header \
            | bedtools sort -header -i - \
        | gzip -c > {output}
        """


rule merge_filtered_snv_by_syntenic:
    input:
        beds=expand(rules.filter_snv_by_syntenic.output, h=[1, 2], allow_missing=True),
    output:
        snv="results/syntenic_and_callable/snv_{sm}.bed.gz",
    log:
        "logs/merge_filtered_snv_by_syntenic.{sm}.log",
    conda:
        "envs/env.yml"
    threads: 1
    script:
        "scripts/implode_snv.py"


rule haplotype_coverage_over_windows:
    input:
        windows=rules.make_windows.output,
        beds=expand(rules.syntenic_and_callable.output, sm=tbl.index, h=[1, 2]),
    output:
        temp("temp/haplotype_coverage.bed.gz"),
    log:
        "logs/haplotype_coverage.log",
    conda:
        "envs/env.yml"
    threads: 1
    params:
        names=" ".join(expand("{sm}_{h}", sm=tbl.index, h=[1, 2])),
        overlap=1 - config["window_size"],  # makes sure bedtools merge only merges the same windows
    shell:
        """
        NUM_COL=$(gunzip -c {input.windows} | head -n 1 | awk '{{print NF}}' || :)
        NAME_COL=$((NUM_COL+1))
        BOOL_COL=$((NUM_COL+2))
        echo $NAME_COL $BOOL_COL

        bedtools intersect -f 0.95 -C \
            -sorted -sortout \
            -a {input.windows} -b {input.beds} \
            -names {params.names} \
        | awk -v bool=$BOOL_COL '$bool != 0' \
        | bedtools merge -i - \
            -d {params.overlap} \
            -c $NAME_COL,$BOOL_COL -o distinct,sum \
        | sed '1s/^/#chr\\tstart\\tend\\thaps\\thap_count\\n/' \
        | gzip -c > {output}
        """


rule clean_annotation_files:
    input:
        annotation_file=lambda w: config["annotation_files"][w.anno],
    output:
        temp("temp/anno/{anno}.bed.gz"),
    log:
        "logs/clean_annotation_files.{anno}.log",
    conda:
        "envs/env.yml"
    threads: 1
    shell:
        """
        bedtools sort -i {input.annotation_file} \
            | bedtools merge -i - \
            | gzip -c > {output}
        """


rule annotate_windows:
    input:
        windows=rules.haplotype_coverage_over_windows.output,
        annotation_files=expand(
            rules.clean_annotation_files.output, anno=config["annotation_files"].keys()
        ),
    output:
        temp("temp/annotated_haplotype_coverage.bed.gz"),
    log:
        "logs/annotate_windows.log",
    conda:
        "envs/env.yml"
    params:
        annotation_names="\t".join(config["annotation_files"].keys()),
    threads: 1
    shell:
        """
        HEADER=$(gunzip -c {input.windows} | head -n 1 || :)
        HEADER="${{HEADER}}\t{params.annotation_names}"
        echo $HEADER
        #echo $HEADER | tr ' ' $"\t" | gzip -c > {output}

        bedtools annotate -i {input.windows} \
                -files {input.annotation_files} \
            | bedtools sort -i - \
            | sed "1s/^/${{HEADER}}\\n/" \
            | gzip -c > {output}
        """


rule uncallable_regions:
    input:
        fai=fai,
        windows=rules.annotate_windows.output,
    output:
        "results/uncallable_regions.bed.gz",
    log:
        "logs/annotate_windows.log",
    conda:
        "envs/env.yml"
    params:
        annotation_names="\t".join(config["annotation_files"].keys()),
    threads: 1
    shell:
        """
        bedtools complement \
            -i <(bedtools merge -i {input.windows}) \
             -g <(cat {input.fai} | sort -k 1,1 -k2,2n ) \
            | gzip -c > {output}
        """


rule add_snv_to_windows:
    input:
        windows=rules.annotate_windows.output,
        snv=expand(rules.filter_snv_by_syntenic.output.snv, sm=tbl.index, h=[1, 2]),
    output:
        "results/snv_count_annotated_haplotype_coverage.bed.gz",
    log:
        "logs/snv_count_windows.log",
    conda:
        "envs/env.yml"
    threads: 1
    shell:
        """
        bedtools coverage \
            -a {input.windows} \
            -b {input.snv} \
            -header -counts -sorted \
        | sed "1s/$/\\tnum_snv/" \
        | gzip -c > {output}
        """


rule all_snv:
    input:
        snv=expand(rules.filter_snv_by_syntenic.output.snv, sm=tbl.index, h=[1, 2]),
    output:
        "results/all_snv_exploded.bed.gz",
    log:
        "logs/snv_count_windows.log",
    conda:
        "envs/env.yml"
    threads: 1
    shell:
        """
        gunzip -c {input.snv} \
            | bedtools sort -i - -header \
        | gzip -c > {output}
        """


rule plot_cumulative_divergence:
    input:
        rules.add_snv_to_windows.output,
    output:
        report(
            "results/figures/cumulative_divergence.svg", category="Figures",
        ),
    log:
        "logs/cumulative_divergence.log",
    conda:
        "envs/R.yml"
    threads: 1
    script:
        "scripts/divergence_cum.R"


rule plot_callable_space:
    input:
        expand(rules.syntenic_and_callable.output, sm=tbl.index, h=[1, 2]),
    output:
        report(
            "results/figures/callable_space.svg", category="Figures",
        ),
    log:
        "logs/callable_space.log",
    conda:
        "envs/R.yml"
    threads: 1
    script:
        "scripts/called_regions.R"
